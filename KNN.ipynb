{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNQ-yjvwkfCQ"
      },
      "source": [
        "# Patch Perfect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbqSfLyfkSXK"
      },
      "source": [
        "## Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTI0-FfpuNIQ",
        "outputId": "f8013e3b-cea5-4bb0-966e-758a0ed54239"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import inference\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "import csv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e0eapzkvn0"
      },
      "source": [
        "## Load Model from RoboFlow and Predict Potholes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkhp-4-yam7N"
      },
      "source": [
        "### Run Object Detection on Train Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "EyQyTbS62JgT",
        "outputId": "8294e517-0a8f-49cf-cef2-aa33df9cbc57"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import inference\n",
        "# Load the model\n",
        "rf = Roboflow(api_key=\"Ujq7MVtbrywY83z9oDsn\")\n",
        "project = rf.workspace(\"pothole\").project(\"stick4\")\n",
        "model = project.version(1).model\n",
        "\n",
        "# Define the confidence and overlap thresholds\n",
        "confidence_threshold = 0.001\n",
        "overlap_threshold = 0.01\n",
        "\n",
        "# Directory where the images are located\n",
        "image_directory = \"drive/MyDrive/data/train_images/\"\n",
        "\n",
        "# Directory where the predictions should be saved\n",
        "predictions_directory = \"drive/MyDrive/data/predictions/\"\n",
        "\n",
        "# Create the predictions directory if it doesn't exist, and clear any existing files in it\n",
        "if os.path.exists(predictions_directory):\n",
        "    # Remove all files in the directory\n",
        "    for filename in os.listdir(predictions_directory):\n",
        "        file_path = os.path.join(predictions_directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "else:\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(predictions_directory)\n",
        "\n",
        "# Get the list of all image files in the directory\n",
        "image_files = sorted([f for f in os.listdir(image_directory) if f.endswith('.jpg')])\n",
        "\n",
        "# Arrays to normalise data later\n",
        "maxPothole = np.zeros(4)\n",
        "maxStick1 = np.zeros(4)\n",
        "maxStick2 = np.zeros(4)\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_directory, image_file)\n",
        "    print(image_file)\n",
        "\n",
        "    try:\n",
        "        # Perform inference on the image with the specified confidence and overlap thresholds\n",
        "        prediction = model.predict(image_path, confidence=confidence_threshold, overlap=overlap_threshold).json()\n",
        "        print(prediction)\n",
        "        # Load the image using OpenCV\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Image {image_path} not found.\")\n",
        "\n",
        "        # Get image dimensions for normalization\n",
        "        img_height, img_width, _ = img.shape\n",
        "\n",
        "        # Separate the predictions by class\n",
        "        pothole_boxes = []\n",
        "        stick_boxes = []\n",
        "        max_confidence = 0\n",
        "        max_confidence1 = 0\n",
        "        max_confidence2 = 0\n",
        "\n",
        "\n",
        "\n",
        "        for bbox in prediction['predictions']:\n",
        "            if bbox['class'] == '0':\n",
        "                pothole_boxes.append(bbox)\n",
        "            elif bbox['class'] == '1' or bbox['class'] == '2':\n",
        "                stick_boxes.append(bbox)\n",
        "\n",
        "        # Create a text file with the same name as the image file (but with a .txt extension)\n",
        "        output_file_name = os.path.join(predictions_directory, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
        "        with open(output_file_name, \"w\") as file:\n",
        "          pothole_array = np.array([-1,-1,-1,-1])\n",
        "          l1_array = np.array([-1,-1,-1,-1])\n",
        "          l2_array = np.array([-1,-1,-1,-1])\n",
        "\n",
        "          # Process the 'pothole' boxes first, if they exist\n",
        "          for bbox in pothole_boxes:\n",
        "              confidence = bbox['confidence']\n",
        "              if confidence > max_confidence:\n",
        "                max_confidence = confidence\n",
        "                x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                if x1 > maxPothole[0]:\n",
        "                  maxPothole[0] = x1\n",
        "                y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                if y1 > maxPothole[1]:\n",
        "                  maxPothole[1] = y1\n",
        "                width = bbox['width'] / img_width\n",
        "                if width > maxPothole[2]:\n",
        "                  maxPothole[2] = width\n",
        "                height = bbox[\"height\"] / img_height\n",
        "                if height > maxPothole[3]:\n",
        "                  maxPothole[3] = height\n",
        "                box_num = bbox['class_id']\n",
        "                pothole_array = np.array([x1, y1, width, height])\n",
        "\n",
        "              # Denormalize for drawing purposes\n",
        "              start_point = (int(x1 * img_width), int(y1 * img_height))\n",
        "              end_point = (int((x1 + width) * img_width), int((y1 + height) * img_height))\n",
        "              color = (0, 255, 0)  # Green color for bounding box\n",
        "              thickness = 2  # Thickness of the bounding box\n",
        "              img = cv2.rectangle(img, start_point, end_point, color, thickness)\n",
        "\n",
        "          # Process the 'stick' boxes\n",
        "          for bbox in stick_boxes:\n",
        "              box_num = bbox['class_id']\n",
        "              confidence = bbox['confidence']\n",
        "              match box_num:\n",
        "                case 1:\n",
        "                  if confidence > max_confidence1:\n",
        "                    max_confidence1 = confidence\n",
        "                    x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                    if x1 > maxStick1[0]:\n",
        "                      maxStick1[0] = x1\n",
        "                    y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                    if y1 > maxStick1[1]:\n",
        "                      maxStick1[1] = y1\n",
        "                    width = bbox['width'] / img_width\n",
        "                    if width > maxStick1[2]:\n",
        "                      maxStick1[2] = width\n",
        "                    height = bbox[\"height\"] / img_height\n",
        "                    if height > maxStick1[3]:\n",
        "                      maxStick1[3] = height\n",
        "                    l1_array = np.array([x1, y1, width, height])\n",
        "                case 2:\n",
        "                  if confidence > max_confidence2:\n",
        "                    max_confidence2 = confidence\n",
        "                    x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                    if x1 > maxStick2[0]:\n",
        "                      maxStick2[0] = x1\n",
        "                    y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                    if y1 > maxStick2[1]:\n",
        "                      maxStick2[1] = y1\n",
        "                    width = bbox['width'] / img_width\n",
        "                    if width > maxStick2[2]:\n",
        "                      maxStick2[2] = width\n",
        "                    height = bbox[\"height\"] / img_height\n",
        "                    if height > maxStick2[3]:\n",
        "                      maxStick2[3] = height\n",
        "                    l2_array = np.array([x1, y1, width, height])\n",
        "\n",
        "              # Denormalize for drawing purposes\n",
        "              start_point = (int(x1 * img_width), int(y1 * img_height))\n",
        "              end_point = (int((x1 + width) * img_width), int((y1 + height) * img_height))\n",
        "              if box_num == 1:\n",
        "                  color = (255, 255, 0)  # Yellow color for class 1\n",
        "              elif box_num == 2:\n",
        "                  color = (0, 255, 255)  # Cyan color for class 2\n",
        "\n",
        "              thickness = 2  # Thickness of the bounding box\n",
        "              img = cv2.rectangle(img, start_point, end_point, color, thickness)\n",
        "\n",
        "          # Display the image with bounding boxes\n",
        "          cv2_imshow(img)\n",
        "          # cv2_waitKey(0)\n",
        "          # cv2.destroyAllWindows()\n",
        "\n",
        "          # Write the normalized bounding box data to the file\n",
        "          file.write(f\"0, {pothole_array[0]:.6f}, {pothole_array[1]:.6f}, {pothole_array[2]:.6f}, {pothole_array[3]:.6f}\\n\")\n",
        "          file.write(f\"1, {l1_array[0]:.6f}, {l1_array[1]:.6f}, {l1_array[2]:.6f}, {l1_array[3]:.6f}\\n\")\n",
        "          file.write(f\"2, {l2_array[0]:.6f}, {l2_array[1]:.6f}, {l2_array[2]:.6f}, {l2_array[3]:.6f}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print error message and continue with the next image\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu6pwW8gawGR"
      },
      "source": [
        "### Run Object Detection on Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6-15wboOap5r",
        "outputId": "fd4d1a23-df0d-46bc-a101-ee1b853f3eca"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import inference\n",
        "# Load the model\n",
        "rf = Roboflow(api_key=\"Ujq7MVtbrywY83z9oDsn\")\n",
        "project = rf.workspace(\"pothole\").project(\"stick4\")\n",
        "model = project.version(1).model\n",
        "\n",
        "# Define the confidence and overlap thresholds\n",
        "confidence_threshold = 0.001\n",
        "overlap_threshold = 0.01\n",
        "\n",
        "# Directory where the images are located\n",
        "image_directory = \"drive/MyDrive/data/test_images/\"\n",
        "\n",
        "# Directory where the predictions should be saved\n",
        "predictions_directory = \"drive/MyDrive/data/predictions_test/\"\n",
        "\n",
        "# Create the predictions directory if it doesn't exist, and clear any existing files in it\n",
        "if os.path.exists(predictions_directory):\n",
        "    # Remove all files in the directory\n",
        "    for filename in os.listdir(predictions_directory):\n",
        "        file_path = os.path.join(predictions_directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "else:\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(predictions_directory)\n",
        "\n",
        "# Get the list of all image files in the directory\n",
        "image_files = sorted([f for f in os.listdir(image_directory) if f.endswith('.jpg')])\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_directory, image_file)\n",
        "    print(image_file)\n",
        "\n",
        "    try:\n",
        "        # Perform inference on the image with the specified confidence and overlap thresholds\n",
        "        prediction = model.predict(image_path, confidence=confidence_threshold, overlap=overlap_threshold).json()\n",
        "        print(prediction)\n",
        "        # Load the image using OpenCV\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Image {image_path} not found.\")\n",
        "\n",
        "        # Get image dimensions for normalization\n",
        "        img_height, img_width, _ = img.shape\n",
        "\n",
        "        # Separate the predictions by class\n",
        "        pothole_boxes = []\n",
        "        stick_boxes = []\n",
        "        max_confidence = 0\n",
        "        max_confidence1 = 0\n",
        "        max_confidence2 = 0\n",
        "\n",
        "\n",
        "\n",
        "        for bbox in prediction['predictions']:\n",
        "            if bbox['class'] == '0':\n",
        "                pothole_boxes.append(bbox)\n",
        "            elif bbox['class'] == '1' or bbox['class'] == '2':\n",
        "                stick_boxes.append(bbox)\n",
        "\n",
        "        # Create a text file with the same name as the image file (but with a .txt extension)\n",
        "        output_file_name = os.path.join(predictions_directory, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
        "        with open(output_file_name, \"w\") as file:\n",
        "          pothole_array = np.array([-1,-1,-1,-1])\n",
        "          l1_array = np.array([-1,-1,-1,-1])\n",
        "          l2_array = np.array([-1,-1,-1,-1])\n",
        "\n",
        "          # Process the 'pothole' boxes first, if they exist\n",
        "          for bbox in pothole_boxes:\n",
        "              confidence = bbox['confidence']\n",
        "              if confidence > max_confidence:\n",
        "                max_confidence = confidence\n",
        "                x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                if x1 > maxPotholeT[0]:\n",
        "                  maxPotholeT[0] = x1\n",
        "                y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                if y1 > maxPotholeT[1]:\n",
        "                  maxPotholeT[1] = y1\n",
        "                width = bbox['width'] / img_width\n",
        "                if width > maxPotholeT[2]:\n",
        "                  maxPotholeT[2] = width\n",
        "                height = bbox[\"height\"] / img_height\n",
        "                if height > maxPotholeT[3]:\n",
        "                  maxPotholeT[3] = height\n",
        "                box_num = bbox['class_id']\n",
        "                pothole_array = np.array([x1, y1, width, height])\n",
        "\n",
        "              # Denormalize for drawing purposes\n",
        "              start_point = (int(x1 * img_width), int(y1 * img_height))\n",
        "              end_point = (int((x1 + width) * img_width), int((y1 + height) * img_height))\n",
        "              color = (0, 255, 0)  # Green color for bounding box\n",
        "              thickness = 2  # Thickness of the bounding box\n",
        "              img = cv2.rectangle(img, start_point, end_point, color, thickness)\n",
        "\n",
        "          # Process the 'stick' boxes\n",
        "          for bbox in stick_boxes:\n",
        "              box_num = bbox['class_id']\n",
        "              confidence = bbox['confidence']\n",
        "              match box_num:\n",
        "                case 1:\n",
        "                  if confidence > max_confidence1:\n",
        "                    max_confidence1 = confidence\n",
        "                    x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                    if x1 > maxStick1T[0]:\n",
        "                      maxStick1T[0] = x1\n",
        "                    y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                    if y1 > maxStick1T[1]:\n",
        "                      maxStick1T[1] = y1\n",
        "                    width = bbox['width'] / img_width\n",
        "                    if width > maxStick1T[2]:\n",
        "                      maxStick1T[2] = width\n",
        "                    height = bbox[\"height\"] / img_height\n",
        "                    if height > maxStick1T[3]:\n",
        "                      maxStick1T[3] = height\n",
        "                    l1_array = np.array([x1, y1, width, height])\n",
        "                case 2:\n",
        "                  if confidence > max_confidence2:\n",
        "                    max_confidence2 = confidence\n",
        "                    x1 = (bbox['x'] - (bbox['width'] / 2)) / img_width\n",
        "                    if x1 > maxStick2T[0]:\n",
        "                      maxStick2T[0] = x1\n",
        "                    y1 = (bbox['y'] - (bbox['height'] / 2)) / img_height\n",
        "                    if y1 > maxStick2T[1]:\n",
        "                      maxStick2T[1] = y1\n",
        "                    width = bbox['width'] / img_width\n",
        "                    if width > maxStick2T[2]:\n",
        "                      maxStick2T[2] = width\n",
        "                    height = bbox[\"height\"] / img_height\n",
        "                    if height > maxStick2T[3]:\n",
        "                      maxStick2T[3] = height\n",
        "                    l2_array = np.array([x1, y1, width, height])\n",
        "\n",
        "              # Denormalize for drawing purposes\n",
        "              start_point = (int(x1 * img_width), int(y1 * img_height))\n",
        "              end_point = (int((x1 + width) * img_width), int((y1 + height) * img_height))\n",
        "              if box_num == 1:\n",
        "                  color = (255, 255, 0)  # Yellow color for class 1\n",
        "              elif box_num == 2:\n",
        "                  color = (0, 255, 255)  # Cyan color for class 2\n",
        "\n",
        "              thickness = 2  # Thickness of the bounding box\n",
        "              img = cv2.rectangle(img, start_point, end_point, color, thickness)\n",
        "\n",
        "          # Display the image with bounding boxes\n",
        "          cv2_imshow(img)\n",
        "          # cv2_waitKey(0)\n",
        "          # cv2.destroyAllWindows()\n",
        "\n",
        "          # Write the normalized bounding box data to the file\n",
        "          file.write(f\"0, {pothole_array[0]:.6f}, {pothole_array[1]:.6f}, {pothole_array[2]:.6f}, {pothole_array[3]:.6f}\\n\")\n",
        "          file.write(f\"1, {l1_array[0]:.6f}, {l1_array[1]:.6f}, {l1_array[2]:.6f}, {l1_array[3]:.6f}\\n\")\n",
        "          file.write(f\"2, {l2_array[0]:.6f}, {l2_array[1]:.6f}, {l2_array[2]:.6f}, {l2_array[3]:.6f}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print error message and continue with the next image\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv221ms1YFmZ"
      },
      "source": [
        "### Normalise Train Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Cqrz2aYEmx"
      },
      "outputs": [],
      "source": [
        "# Function to normalize a row based on its class\n",
        "def normalize_row(row, max_values):\n",
        "    # Normalize each value by the corresponding max value, skip normalization for -1\n",
        "    normalized_values = [(value / max_val if max_val != 0 and value != -1 else value)\n",
        "                         for value, max_val in zip(row[1:], max_values)]\n",
        "    return [row[0]] + normalized_values\n",
        "\n",
        "# Directory where the .txt files are located\n",
        "predictions_directory = \"drive/MyDrive/data/predictions/\"\n",
        "\n",
        "# Directory to save normalized .txt files\n",
        "normalized_directory = \"drive/MyDrive/data/predictions_train_normalized/\"\n",
        "if os.path.exists(normalized_directory):\n",
        "    # Remove all files in the directory\n",
        "    for filename in os.listdir(normalized_directory):\n",
        "        file_path = os.path.join(normalized_directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "else:\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(normalized_directory)\n",
        "\n",
        "# Loop through each .txt file in the directory\n",
        "for txt_file in os.listdir(predictions_directory):\n",
        "    if txt_file.endswith(\".txt\"):\n",
        "        txt_file_path = os.path.join(predictions_directory, txt_file)\n",
        "        normalized_txt_file_path = os.path.join(normalized_directory, txt_file)\n",
        "\n",
        "        # Open the file to read and normalize\n",
        "        with open(txt_file_path, \"r\") as infile, open(normalized_txt_file_path, \"w\") as outfile:\n",
        "            for line in infile:\n",
        "                values = list(map(float, line.strip().split(\",\")))\n",
        "                box_id = int(values[0])\n",
        "                row_values = np.array(values)\n",
        "\n",
        "                if box_id == 0:\n",
        "                    max_values = maxPothole\n",
        "                elif box_id == 1:\n",
        "                    max_values = maxStick1\n",
        "                elif box_id == 2:\n",
        "                    max_values = maxStick2\n",
        "                else:\n",
        "                    continue  # Skip rows with unknown box IDs\n",
        "\n",
        "                # Normalize the row values\n",
        "                normalized_row = normalize_row(row_values, max_values)\n",
        "\n",
        "                # Write the normalized values to the output file\n",
        "                outfile.write(\",\".join(map(str, normalized_row)) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLCV71V8gvGr"
      },
      "source": [
        "### Normalise Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjSO22b4gnm2"
      },
      "outputs": [],
      "source": [
        "# Function to normalize a row based on its class\n",
        "def normalize_row(row, max_values):\n",
        "    # Normalize each value by the corresponding max value, skip normalization for -1\n",
        "    normalized_values = [(value / max_val if max_val != 0 and value != -1 else value)\n",
        "                         for value, max_val in zip(row[1:], max_values)]\n",
        "    return [row[0]] + normalized_values\n",
        "\n",
        "# Directory where the .txt files are located\n",
        "predictions_directory = \"drive/MyDrive/data/predictions_test/\"\n",
        "\n",
        "# Directory to save normalized .txt files\n",
        "normalized_directory = \"drive/MyDrive/data/predictions_test_normalized/\"\n",
        "if os.path.exists(normalized_directory):\n",
        "    # Remove all files in the directory\n",
        "    for filename in os.listdir(normalized_directory):\n",
        "        file_path = os.path.join(normalized_directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}: {e}\")\n",
        "else:\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(normalized_directory)\n",
        "\n",
        "# Loop through each .txt file in the directory\n",
        "for txt_file in os.listdir(predictions_directory):\n",
        "    if txt_file.endswith(\".txt\"):\n",
        "        txt_file_path = os.path.join(predictions_directory, txt_file)\n",
        "        normalized_txt_file_path = os.path.join(normalized_directory, txt_file)\n",
        "\n",
        "        # Open the file to read and normalize\n",
        "        with open(txt_file_path, \"r\") as infile, open(normalized_txt_file_path, \"w\") as outfile:\n",
        "            for line in infile:\n",
        "                values = list(map(float, line.strip().split(\",\")))\n",
        "                box_id = int(values[0])\n",
        "                row_values = np.array(values)\n",
        "\n",
        "                if box_id == 0:\n",
        "                    max_values = maxPotholeT\n",
        "                elif box_id == 1:\n",
        "                    max_values = maxStick1T\n",
        "                elif box_id == 2:\n",
        "                    max_values = maxStick2T\n",
        "                else:\n",
        "                    continue  # Skip rows with unknown box IDs\n",
        "\n",
        "                # Normalize the row values\n",
        "                normalized_row = normalize_row(row_values, max_values)\n",
        "\n",
        "                # Write the normalized values to the output file\n",
        "                outfile.write(\",\".join(map(str, normalized_row)) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZasUQ0cij6N"
      },
      "outputs": [],
      "source": [
        "# Function to load prediction data from a .txt file and convert it into a feature vector\n",
        "def load_prediction_data(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        # Read all lines, skipping the header\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Extract and flatten the numeric values from each line\n",
        "    features = []\n",
        "    for line in lines:\n",
        "        values = line.strip().split(\",\")[1:]  # Skip the first column (box number)\n",
        "        features.extend([float(v) for v in values])\n",
        "\n",
        "    return np.array(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc-c_s3TJyTv"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "nKn5-dkvJzy0",
        "outputId": "796edcb1-620c-4975-9c9a-bcd82e38d9e0"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "predictions_directory = \"drive/MyDrive/data/predictions/\"\n",
        "csv_file = \"drive/MyDrive/data/train_labels.csv\"\n",
        "\n",
        "labels_df = pd.read_csv(csv_file)\n",
        "# print(labels_df)\n",
        "\n",
        "# Prepare the dataset by matching prediction data with labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for index, row in labels_df.iterrows():\n",
        "    txt_file_name = f\"p{int(row['Pothole number'])}.txt\"\n",
        "    txt_file_path = os.path.join(predictions_directory, txt_file_name)\n",
        "\n",
        "    if os.path.exists(txt_file_path):\n",
        "        # Load the prediction data\n",
        "        features = load_prediction_data(txt_file_path)\n",
        "        data.append(features)\n",
        "\n",
        "        # Get the corresponding bags_used value\n",
        "        labels.append(row['Bags used '])\n",
        "\n",
        "\n",
        "data = np.array(data)[:,:8]\n",
        "print(data.shape)\n",
        "\n",
        "wp = data[:,0]\n",
        "hp = data[:,1]\n",
        "ws = data[:,2]\n",
        "hs = data[:,3]\n",
        "\n",
        "# data = [wp, hp, ws, hs, data[:,4], data[:,5], data[:,6], data[:,7]]\n",
        "print(data[:,1])\n",
        "\n",
        "\n",
        "\n",
        "dataInput = list(zip(ws, hs, data[:,6], data[:,7]))\n",
        "\n",
        "# print(dataInput)\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(dataInput, labels)\n",
        "\n",
        "predictions = np.zeros_like(labels)\n",
        "for i in range(len(labels)):\n",
        "    input_data = np.array(dataInput[i]).reshape(1, -1)\n",
        "    # print(input_data)\n",
        "    predictions[i] = knn.predict(input_data)\n",
        "# print(predictions)\n",
        "\n",
        "plt.plot(labels, c='blue')\n",
        "plt.plot(predictions, c='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QgXOLWuzu4-L",
        "outputId": "8d423312-0d8d-4058-c5e2-576f25f60753"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate predictions\n",
        "predictions = np.zeros_like(labels)\n",
        "for i in range(len(labels)):\n",
        "    input_data = np.array(dataInput[i]).reshape(1, -1)\n",
        "    predictions[i] = knn.predict(input_data)\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(labels, predictions)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Calculate R^2 error\n",
        "r2 = r2_score(labels, predictions)\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "\n",
        "x=np.linspace(0,len(labels),len(labels))\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(x,labels, c='blue', label='True Values')\n",
        "plt.scatter(x,predictions, c='red', label='Predictions')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MlVLpZL2ccs3",
        "outputId": "ce8b2a5d-75e5-433b-f381-d09b90a07302"
      },
      "outputs": [],
      "source": [
        "predictions_directory = \"drive/MyDrive/data/predictions/\"\n",
        "predictions_test_directory = \"/content/drive/MyDrive/data/predictions_test\"\n",
        "csv_file = \"drive/MyDrive/data/test_labels.csv\"\n",
        "\n",
        "labels_df = pd.read_csv(csv_file)\n",
        "# print(labels_df)\n",
        "\n",
        "# Prepare the dataset by matching prediction data with labels\n",
        "data = []\n",
        "labels = []\n",
        "image = []\n",
        "\n",
        "for index, row in labels_df.iterrows():\n",
        "    txt_file_name = f\"p{int(row['Pothole number'])}.txt\"\n",
        "    txt_file_path = os.path.join(predictions_test_directory, txt_file_name)\n",
        "    image.append(txt_file_name)\n",
        "\n",
        "    if os.path.exists(txt_file_path):\n",
        "        # Load the prediction data\n",
        "        features = load_prediction_data(txt_file_path)\n",
        "        data.append(features)\n",
        "\n",
        "        # Get the corresponding bags_used value\n",
        "        labels.append(row['Bags used '])\n",
        "\n",
        "print(data)\n",
        "\n",
        "\n",
        "data = np.array(data)[:,:8]\n",
        "print(data.shape)\n",
        "\n",
        "wp = data[:,0]\n",
        "hp = data[:,1]\n",
        "ws = data[:,2]\n",
        "hs = data[:,3]\n",
        "\n",
        "# data = [wp, hp, ws, hs, data[:,4], data[:,5], data[:,6], data[:,7]]\n",
        "print(data[:,1])\n",
        "\n",
        "\n",
        "\n",
        "dataInput = list(zip(ws, hs, data[:,6], data[:,7]))\n",
        "\n",
        "# print(dataInput)\n",
        "# knn = KNeighborsRegressor(n_neighbors=5)\n",
        "# knn.fit(dataInput, labels)\n",
        "\n",
        "predictions = np.zeros(30)\n",
        "for i in range(len(predictions)):\n",
        "    input_data = np.array(dataInput[i]).reshape(1, -1)\n",
        "    # print(input_data)\n",
        "    predictions[i] = np.round(knn.predict(input_data),2)\n",
        "    print(f\"{image[i][1:-4]},{predictions[i]:.2f}\")\n",
        "# print(predictions)\n",
        "\n",
        "# plt.plot(labels, c='blue')\n",
        "plt.plot(predictions, c='red')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
